"""
Video Analyzer using Claude 3.5 Sonnet Vision API.
"""

import os
import subprocess
import base64
import json
import re
import time
from typing import Optional, Dict
from utils.logger import setup_logger

logger = setup_logger(__name__)
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "")


def extract_video_frames(video_path: str, timestamps: list = None) -> list:
    """
    Extract frames from video using ffmpeg.

    Args:
        video_path: Path to video file
        timestamps: List of timestamps in seconds (default: [0, 3, 10])
                   - 0s: Hook (first 3 seconds)
                   - 3s: Body/Transition
                   - 10s: CTA/End

    Returns:
        List of base64-encoded frame images
    """
    if timestamps is None:
        timestamps = [0, 3, 10]  # Optimize for Hook, Body, CTA

    frames = []
    try:
        # Get duration to validate timestamps
        duration_cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            video_path
        ]
        duration = float(subprocess.check_output(duration_cmd).decode().strip())

        # Adjust timestamps if video is shorter
        adjusted_timestamps = [min(t, duration - 0.1) for t in timestamps]

        for i, timestamp in enumerate(adjusted_timestamps):
            output_path = f"/tmp/frame_{i}_{int(timestamp)}s.png"

            extract_cmd = [
                "ffmpeg",
                "-ss", str(timestamp),  # Seek to timestamp
                "-i", video_path,
                "-vframes", "1",  # Extract 1 frame
                "-q:v", "2",  # Quality (2 = high)
                "-y",  # Overwrite
                output_path
            ]
            subprocess.run(extract_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)

            with open(output_path, "rb") as f:
                frame_b64 = base64.b64encode(f.read()).decode('utf-8')
                frames.append({
                    "data": frame_b64,
                    "timestamp": timestamp,
                    "label": _get_frame_label(timestamp)
                })
            os.remove(output_path)

        logger.info(f"âœ… Extracted {len(frames)} frames at {timestamps}s")
        return frames
    except Exception as e:
        logger.error(f"Frame extraction failed: {e}")
        return []


def _get_frame_label(timestamp: float) -> str:
    """Get semantic label for frame based on timestamp."""
    if timestamp <= 1:
        return "hook"
    elif timestamp <= 5:
        return "transition"
    else:
        return "cta"


def analyze_video_with_claude(video_path: str) -> Optional[Dict]:
    """Analyze video using Claude Vision API."""
    if not ANTHROPIC_API_KEY:
        logger.warning("ANTHROPIC_API_KEY not set")
        return None

    # Handle R2 paths - download video first
    local_video_path = video_path
    cleanup_needed = False

    if video_path.startswith('r2://'):
        try:
            from utils.storage import get_storage
            import tempfile

            logger.info(f"Downloading video from R2: {video_path}")
            storage = get_storage()

            # Download video to temp file
            video_content = storage.get_file_content(video_path)
            if not video_content:
                logger.error(f"Failed to download video from R2: {video_path}")
                return None

            # Save to temp file
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            temp_file.write(video_content)
            temp_file.close()
            local_video_path = temp_file.name
            cleanup_needed = True
            logger.info(f"Video downloaded to: {local_video_path}")
        except Exception as e:
            logger.error(f"Failed to download R2 video: {e}")
            return None
    else:
        # Local file path - check if file exists
        if not os.path.exists(video_path):
            # Fallback: if /tmp/ file not found, try to find in R2 by filename
            if video_path.startswith('/tmp/'):
                logger.warning(f"Local file not found: {video_path}, trying R2 fallback...")
                filename = os.path.basename(video_path)
                # Try R2 path: r2://client-assets/{user_id}/{filename}
                # For now, just return None - user should re-upload
                logger.error(f"Video file not found: {video_path}. Please re-upload the creative.")
                return None
            logger.error(f"Video file not found: {video_path}")
            return None
        logger.info(f"Analyzing local video: {video_path}")

    frames = extract_video_frames(local_video_path)

    # Cleanup temp file if we downloaded from R2
    if cleanup_needed and os.path.exists(local_video_path):
        try:
            os.unlink(local_video_path)
            logger.info(f"Cleaned up temp file: {local_video_path}")
        except Exception as e:
            logger.warning(f"Failed to cleanup temp file: {e}")

    if not frames:
        return None

    prompt = """Analyze this EDTECH or HEALTH & FITNESS UGC video from 3 key frames (Hook at 0s, Body at 3s, CTA at 10s).

**Ð’ÐÐ–ÐÐž:** Ð¡Ñ€Ð°Ð²Ð½Ð¸ ÑÑ‚Ð¾ Ð²Ð¸Ð´ÐµÐ¾ Ñ ÑÑ‚Ð°Ð»Ð¾Ð½Ð°Ð¼Ð¸ Ñ€Ñ‹Ð½ÐºÐ° (Facebook Ad Library, TikTok Creative Center) Ð¸ Ð²Ñ‹Ð´ÐµÐ»Ð¸ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð²Ð»Ð¸ÑÑŽÑ‚ Ð½Ð° RETENTION (ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹), Ð° Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸.

**Ð¢ÐÐšÐ–Ð•:** Ð Ð°ÑÐºÐ»Ð°Ð´Ñ‹Ð²Ð°Ð¹ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑÑ‚Ð°Ð¿Ðµ - ÑÑ‚Ð¾ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð´Ð»Ñ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ!

Extract the following:

1. **hook_type**: (Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ð¾Ð´Ð¸Ð½)
   - **transformation**: Ð”Ð¾/ÐŸÐ¾ÑÐ»Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ Ð´Ð»Ñ Health)
   - **problem_solution**: ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° â†’ Ð ÐµÑˆÐµÐ½Ð¸Ðµ (Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ Ð´Ð»Ñ EdTech)
   - **gamification**: Ð“ÐµÐ¹Ð¼Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ, Ñ‡ÐµÐ»Ð»ÐµÐ½Ð´Ð¶Ð¸, Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ
   - **question**: ÐŸÑ€Ð¾Ð²Ð¾ÐºÐ°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ
   - **social_proof**: ÐžÑ‚Ð·Ñ‹Ð²Ñ‹, Ñ†Ð¸Ñ„Ñ€Ñ‹, Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°
   - **insider_secret**: Ð¡ÐµÐºÑ€ÐµÑ‚ Ð¸Ð»Ð¸ Ð¸Ð½ÑÐ°Ð¹Ð´
   - **urgency**: Ð¡Ñ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ, Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸

2. **emotion**: frustration, achievement, curiosity, trust, hope, fomo, empathy, neutral

3. **pacing**: fast, medium, slow

4. **retention_triggers** (ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ð¾Ð²Ñ‹ÑˆÐ°ÑŽÑ‚ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ):
   - **progress_bar**: ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ-Ð±Ð°Ñ€Ñ‹, Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ð¹
   - **community**: ÐšÐ¾Ð¼ÑŒÑŽÐ½Ð¸Ñ‚Ð¸, ÑÐ¾Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹, ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð½Ñ‹Ðµ Ñ‡ÐµÐ»Ð»ÐµÐ½Ð´Ð¶Ð¸
   - **habit_formation**: Ð­Ð»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¿Ñ€Ð¸Ð²Ñ‹Ñ‡ÐºÐ¸ (Ð½Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ, streak, ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸)
   - **personalization**: ÐŸÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð° Ð¿Ð¾Ð´ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
   - **micro_wins**: Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð¿Ð¾Ð±ÐµÐ´Ñ‹, Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð°Ñ ÑÐ²ÑÐ·ÑŒ
   - **none**: ÐÐµÑ‚ ÑÐ²Ð½Ñ‹Ñ… retention Ñ‚Ñ€Ð¸Ð³Ð³ÐµÑ€Ð¾Ð²

5. **visual_elements** (Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ):
   - **ugc**: UGC ÑÑ‚Ð¸Ð»ÑŒ, ÑÑŠÐµÐ¼ÐºÐ° Ð½Ð° ÑÐ¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½, ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ðµ Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ðµ
   - **screen_recording**: Screen recording Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ/Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°
   - **animation**: ÐÐ½Ð¸Ð¼Ð°Ñ†Ð¸Ñ, Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ°, motion design
   - **before_after**: Ð’Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð”Ð¾/ÐŸÐ¾ÑÐ»Ðµ
   - **talking_head**: Ð“Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð°Ñ Ð³Ð¾Ð»Ð¾Ð²Ð° (Ð¿Ñ€ÑÐ¼Ð¾ Ð² ÐºÐ°Ð¼ÐµÑ€Ñƒ)

6. **niche_specific** (Ð°Ð½Ð°Ð»Ð¸Ð· Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð½Ð¸ÑˆÐ¸):
   - Ð”Ð»Ñ **HEALTH**: Ð¤Ð¾ÐºÑƒÑ Ð½Ð° Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½ÑƒÑŽ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ, Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹, Ð”Ð¾/ÐŸÐ¾ÑÐ»Ðµ
   - Ð”Ð»Ñ **EDTECH**: Ð¤Ð¾ÐºÑƒÑ Ð½Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°, Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ð¹ Ð¾Ñ„Ñ„ÐµÑ€, Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹

7. **target_audience_pain**: no_time, lack_results, fear_missing_out, overwhelmed, skepticism, tried_everything, lack_knowledge, unknown

8. **psychotype** (target audience psychological profile):
   - **Switcher**: ÐŸÐ¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾ Ð¸Ñ‰ÐµÑ‚ "Ð¸Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ", Ð½ÐµÑ‚ÐµÑ€Ð¿ÐµÐ»Ð¸Ð²Ñ‹Ð¹
   - **Status Seeker**: ÐœÐ¾Ñ‚Ð¸Ð²Ð¸Ñ€Ð¾Ð²Ð°Ð½ ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð°Ð¼Ð¸, ÐºÐ°Ñ€ÑŒÐµÑ€Ð¾Ð¹
   - **Skill Upgrader**: ÐŸÑ€Ð°ÐºÑ‚Ð¸Ðº, Ñ…Ð¾Ñ‡ÐµÑ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð½Ð°Ð²Ñ‹ÐºÐ¸ Ð¡Ð•Ð™Ð§ÐÐ¡
   - **Freedom Hunter**: Ð¦ÐµÐ½Ð¸Ñ‚ Ð³Ð¸Ð±ÐºÐ¾ÑÑ‚ÑŒ Ð¸ ÑÐ²Ð¾Ð±Ð¾Ð´Ñƒ, Ñ…Ð¾Ñ‡ÐµÑ‚ escape 9-5
   - **Safety Seeker**: Ð˜Ð·Ð±ÐµÐ³Ð°ÐµÑ‚ Ñ€Ð¸ÑÐºÐ¾Ð², Ð½ÑƒÐ¶Ð½Ñ‹ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¸

9. **winning_elements** (Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°ÐµÑ‚ ÑÑ‚Ð¾ Ð²Ð¸Ð´ÐµÐ¾ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¾Ð½Ð½Ñ‹Ð¼ Ñ…Ð¸Ñ‚Ð¾Ð¼):
   - Ð’Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ (Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÑÐºÑ€Ð°Ð½Ðµ, b-roll, Ð»Ð¸Ñ†Ð¾ ÑÐ¿Ð¸ÐºÐµÑ€Ð°, ÑÑƒÐ±Ñ‚Ð¸Ñ‚Ñ€Ñ‹)
   - Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° (Hook â†’ Problem â†’ Solution â†’ CTA)
   - Ð¢Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ (authenticity, urgency, empathy)
   - Retention-focused ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ (Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ, ÐºÐ¾Ð¼ÑŒÑŽÐ½Ð¸Ñ‚Ð¸, Ð¿Ñ€Ð¸Ð²Ñ‹Ñ‡ÐºÐ¸)
   - ÐžÑ‚Ð»Ð¸Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²

10. **timeline** (Ñ€Ð°Ð·Ð±Ð¸Ð²ÐºÐ° Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ - Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑÑ‚Ð°Ð¿Ðµ):
   Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ñ„Ñ€ÐµÐ¹Ð¼Ð° ÑƒÐºÐ°Ð¶Ð¸:
   - **timestamp**: "0-3s" | "3-10s" | "10-15s"
   - **what_happens**: Ð§Ñ‚Ð¾ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð² ÐºÐ°Ð´Ñ€Ðµ (Ñ‚ÐµÐºÑÑ‚, Ð²Ð¸Ð·ÑƒÐ°Ð»Ñ‹, Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ)
   - **emotion_shift**: ÐšÐ°Ðº Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ ÑÐ¼Ð¾Ñ†Ð¸Ñ Ð·Ñ€Ð¸Ñ‚ÐµÐ»Ñ
   - **retention_hook**: Ð§Ñ‚Ð¾ ÑƒÐ´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð° ÑÑ‚Ð¾Ð¼ ÑÑ‚Ð°Ð¿Ðµ
   - **cta_presence**: Ð•ÑÑ‚ÑŒ Ð»Ð¸ Ð¿Ñ€Ð¸Ð·Ñ‹Ð² Ðº Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸ÑŽ

Respond ONLY in valid JSON format:
{
  "hook_type": "...",
  "emotion": "...",
  "pacing": "...",
  "retention_triggers": "...",
  "visual_elements": "...",
  "niche_specific": "...",
  "target_audience_pain": "...",
  "psychotype": "...",
  "winning_elements": "...",
  "timeline": [
    {
      "timestamp": "0-3s",
      "what_happens": "...",
      "emotion_shift": "...",
      "retention_hook": "...",
      "cta_presence": false
    },
    {
      "timestamp": "3-10s",
      "what_happens": "...",
      "emotion_shift": "...",
      "retention_hook": "...",
      "cta_presence": false
    },
    {
      "timestamp": "10-15s",
      "what_happens": "...",
      "emotion_shift": "...",
      "retention_hook": "...",
      "cta_presence": true
    }
  ],
  "reasoning": "..."
}"""

    try:
        import anthropic
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

        content = [{"type": "text", "text": prompt}]

        # Add frames with labels for context
        for frame in frames:
            frame_label = frame.get("label", "unknown")
            timestamp = frame.get("timestamp", 0)

            # Add context for each frame
            content.append({
                "type": "text",
                "text": f"\n[Frame at {timestamp}s - {frame_label.upper()}]:"
            })
            content.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/png",
                    "data": frame["data"]
                }
            })
        
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,
            messages=[{"role": "user", "content": content}]
        )
        
        response_text = response.content[0].text
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        result = json.loads(json_match.group(1) if json_match else response_text)

        # DEBUG: Log full response to see what Claude returns
        logger.info(f"ðŸ” FULL CLAUDE RESPONSE (first 2000 chars): {json.dumps(result, ensure_ascii=False)[:2000]}")
        logger.info(f"ðŸ” HAS TIMELINE: {'timeline' in result} | HAS FEATURES: {result.get('timeline') is not None}")
        logger.info(f"âœ… Claude analyzed: {result.get('hook_type', 'unknown')} + {result.get('emotion', 'unknown')}")
        return result
    except Exception as e:
        logger.error(f"Claude API error: {e}")
        return None


def analyze_video_with_retry(video_path: str, max_retries: int = 3) -> Dict:
    """Analyze with retries."""
    for attempt in range(max_retries):
        result = analyze_video_with_claude(video_path)
        if result:
            return result
        if attempt < max_retries - 1:
            time.sleep(2 ** attempt)
    
    return {
        "hook_type": "unknown",
        "emotion": "unknown",
        "pacing": "medium",
        "target_audience_pain": "unknown",
        "psychotype": "unknown",
        "retention_triggers": "unknown",
        "visual_elements": "unknown",
        "niche_specific": "unknown",
        "winning_elements": "Video file not found or analysis failed. Please re-upload the creative.",
        "timeline": [],
        "reasoning": "AI analysis failed - video file not found or Claude API error"
    }
