"""
Thompson Sampling Helpers - –∑–∞—â–∏—Ç–∞ –æ—Ç —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è exploration.

–ü—Ä–æ–±–ª–µ–º—ã —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞:
1. –ù–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –±–∞–∑–µ ‚Üí —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∑–Ω–∞–µ—Ç, —á—Ç–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å
2. –ü–µ—Ä–≤—ã–π –∫—Ä–µ–∞—Ç–∏–≤ —Å–ª—É—á–∞–π–Ω–æ —Å—Ä–∞–±–æ—Ç–∞–ª ‚Üí —Å–∏—Å—Ç–µ–º–∞ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –Ω–µ–º

–†–µ—à–µ–Ω–∏—è:
1. Seed patterns - —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è exploration
2. Exploration bonus - –±–æ–Ω—É—Å –¥–ª—è –Ω–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
3. Regret monitoring - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —É–ø—É—â–µ–Ω–Ω–æ–π –≤—ã–≥–æ–¥—ã
"""

from typing import List, Dict
import random
from sqlalchemy.orm import Session
from database.models import PatternPerformance
from utils.logger import setup_logger

logger = setup_logger(__name__)


# EdTech seed patterns (—Å—Ç–∞—Ä—Ç–æ–≤—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –¥–ª—è exploration)
EDTECH_SEED_PATTERNS = [
    # Programming niche
    {
        "hook_type": "question",
        "emotion": "curiosity",
        "pacing": "fast",
        "cta_type": "urgency",
        "target_audience_pain": "no_time",
        "description": "Question hook + curiosity + urgency (classic EdTech)"
    },
    {
        "hook_type": "bold_claim",
        "emotion": "excitement",
        "pacing": "fast",
        "cta_type": "direct",
        "target_audience_pain": "fear_failure",
        "description": "Bold claim + excitement (achievement-focused)"
    },
    {
        "hook_type": "wait",
        "emotion": "curiosity",
        "pacing": "medium",
        "cta_type": "soft",
        "target_audience_pain": "no_progress",
        "description": "Wait hook + curiosity (mystery-based)"
    },
    # Design niche
    {
        "hook_type": "question",
        "emotion": "greed",
        "pacing": "fast",
        "cta_type": "urgency",
        "target_audience_pain": "too_expensive",
        "description": "Question + greed (price-focused)"
    },
    # Career switch niche
    {
        "hook_type": "bold_claim",
        "emotion": "fear",
        "pacing": "fast",
        "cta_type": "scarcity",
        "target_audience_pain": "need_career_switch",
        "description": "Bold claim + fear + scarcity (FOMO-driven)"
    },
]


def create_seed_patterns(
    db: Session,
    user_id: str,
    product_category: str,
    force: bool = False
) -> int:
    """
    –°–æ–∑–¥–∞–µ—Ç seed patterns –¥–ª—è —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞.

    Args:
        db: Database session
        user_id: User UUID
        product_category: Product category
        force: –°–æ–∑–¥–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É–∂–µ –µ—Å—Ç—å

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö seed patterns

    Usage:
        ```python
        from utils.thompson_sampling_helpers import create_seed_patterns

        n_created = create_seed_patterns(
            db=db,
            user_id="user-uuid",
            product_category="language_learning",
            force=False
        )

        print(f"Created {n_created} seed patterns")
        ```
    """

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —É–∂–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    if not force:
        existing_count = db.query(PatternPerformance).filter(
            PatternPerformance.user_id == user_id,
            PatternPerformance.product_category == product_category
        ).count()

        if existing_count > 0:
            logger.info(f"Seed patterns not needed - {existing_count} patterns already exist")
            return 0

    # –°–æ–∑–¥–∞—Ç—å seed patterns
    created = 0

    for seed in EDTECH_SEED_PATTERNS:
        # –°–æ–∑–¥–∞—Ç—å pattern_hash
        pattern_hash = (
            f"hook:{seed['hook_type']}"
            f"|emo:{seed['emotion']}"
            f"|pace:{seed['pacing']}"
            f"|pain:{seed['target_audience_pain']}"
            f"|cta:{seed['cta_type']}"
        )

        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ
        existing = db.query(PatternPerformance).filter(
            PatternPerformance.pattern_hash == pattern_hash,
            PatternPerformance.product_category == product_category
        ).first()

        if existing and not force:
            continue

        # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω —Å –Ω—É–ª–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ (exploration)
        import uuid
        pattern = PatternPerformance(
            id=uuid.uuid4(),
            user_id=user_id,
            pattern_hash=pattern_hash,
            hook_type=seed['hook_type'],
            emotion=seed['emotion'],
            pacing=seed['pacing'],
            cta_type=seed['cta_type'],
            target_audience_pain=seed['target_audience_pain'],
            product_category=product_category,
            sample_size=0,
            total_impressions=0,
            total_clicks=0,
            total_conversions=0,
            total_revenue=0,
            avg_cvr=0,
            avg_ctr=0,
            avg_roas=0,
            confidence_interval_lower=0,
            confidence_interval_upper=0
        )

        db.add(pattern)
        created += 1

    db.commit()

    logger.info(f"‚úÖ Created {created} seed patterns for {product_category}")

    return created


def thompson_sampling_with_exploration_bonus(
    patterns: List[PatternPerformance],
    n_samples: int = 5,
    exploration_bonus: float = 0.05
) -> List[Dict]:
    """
    Thompson Sampling —Å –±–æ–Ω—É—Å–æ–º –¥–ª—è –Ω–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (exploration).

    –î–æ–±–∞–≤–ª—è–µ—Ç exploration_bonus –∫ thompson_score –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –º–∞–ª–æ–π –≤—ã–±–æ—Ä–∫–æ–π.

    Args:
        patterns: –°–ø–∏—Å–æ–∫ PatternPerformance –æ–±—ä–µ–∫—Ç–æ–≤
        n_samples: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        exploration_bonus: –ë–æ–Ω—É—Å –¥–ª—è –Ω–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (0.0 - 0.1)

    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å thompson_score + exploration_bonus

    –ü—Ä–∏–º–µ—Ä:
        - –ü–∞—Ç—Ç–µ—Ä–Ω —Å sample_size=0: bonus = 0.05
        - –ü–∞—Ç—Ç–µ—Ä–Ω —Å sample_size=10: bonus = 0.025
        - –ü–∞—Ç—Ç–µ—Ä–Ω —Å sample_size=50+: bonus = 0
    """

    recommendations = []

    for pattern in patterns:
        total_conversions = pattern.total_conversions or 0
        total_clicks = pattern.total_clicks or 0

        # Beta –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        alpha = 1.0 + total_conversions
        beta_param = 1.0 + max(0, total_clicks - total_conversions)

        # Thompson Sampling
        thompson_score = random.betavariate(alpha, beta_param)

        # Exploration bonus (—É–º–µ–Ω—å—à–∞–µ—Ç—Å—è —Å —Ä–æ—Å—Ç–æ–º sample_size)
        sample_size = pattern.sample_size or 0
        bonus = exploration_bonus * max(0, 1 - sample_size / 50)

        final_score = thompson_score + bonus

        # Mean CVR
        mean_cvr = alpha / (alpha + beta_param)

        recommendations.append({
            "pattern_hash": pattern.pattern_hash,
            "hook_type": pattern.hook_type,
            "emotion": pattern.emotion,
            "pacing": pattern.pacing,
            "target_audience_pain": pattern.target_audience_pain,
            "thompson_score": thompson_score,
            "exploration_bonus": bonus,
            "final_score": final_score,
            "mean_cvr": mean_cvr,
            "sample_size": sample_size,
            "total_conversions": total_conversions,
            "alpha": alpha,
            "beta": beta_param,
            "reasoning": (
                f"High confidence winner (n={sample_size})" if sample_size > 20
                else f"Promising, needs more data (n={sample_size})" if sample_size > 5
                else f"New pattern, high exploration value (bonus={bonus:.3f})"
            )
        })

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ final_score (thompson_score + exploration_bonus)
    recommendations.sort(key=lambda x: x['final_score'], reverse=True)

    return recommendations[:n_samples]


def calculate_regret(
    actual_pattern: str,
    best_pattern: str,
    actual_cvr: float,
    best_cvr: float,
    n_trials: int
) -> Dict:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç regret (—É–ø—É—â–µ–Ω–Ω—É—é –≤—ã–≥–æ–¥—É) –æ—Ç –≤—ã–±–æ—Ä–∞ –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞.

    Regret = (Best CVR - Actual CVR) * N trials

    Args:
        actual_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–±—Ä–∞–ª–∏
        best_pattern: –õ—É—á—à–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω (–≤ hindsight)
        actual_cvr: CVR –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        best_cvr: CVR –ª—É—á—à–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        n_trials: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials (impressions/clicks)

    Returns:
        {
            "regret": 0.05,  # –£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã–≥–æ–¥–∞ (5%)
            "regret_conversions": 5,  # –£–ø—É—â–µ–Ω–Ω—ã–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
            "actual_pattern": "hook:question|...",
            "best_pattern": "hook:bold_claim|...",
            "recommendation": "..."
        }

    –¶–µ–ª—å Thompson Sampling: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å cumulative regret.
    """

    regret = best_cvr - actual_cvr
    regret_conversions = regret * n_trials

    return {
        "regret": round(regret, 4),
        "regret_percent": round(regret * 100, 2),
        "regret_conversions": int(regret_conversions),
        "actual_pattern": actual_pattern,
        "best_pattern": best_pattern,
        "actual_cvr": round(actual_cvr, 4),
        "best_cvr": round(best_cvr, 4),
        "n_trials": n_trials,
        "recommendation": (
            "Low regret - good exploration!" if abs(regret) < 0.02
            else "Moderate regret - acceptable" if abs(regret) < 0.05
            else "High regret - consider adjusting exploration bonus"
        )
    }


def simulate_thompson_sampling_performance(
    patterns: List[Dict],
    n_simulations: int = 1000
) -> Dict:
    """
    –°–∏–º—É–ª—è—Ü–∏—è Thompson Sampling –¥–ª—è –æ—Ü–µ–Ω–∫–∏ exploration/exploitation –±–∞–ª–∞–Ω—Å–∞.

    Args:
        patterns: –°–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å true_cvr
            [{"pattern": "A", "true_cvr": 0.15}, ...]
        n_simulations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º—É–ª—è—Ü–∏–π

    Returns:
        {
            "average_regret": 0.03,
            "best_pattern_selected_pct": 0.75,
            "exploration_rate": 0.25
        }
    """

    if not patterns:
        return {"error": "No patterns provided"}

    # –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
    best_pattern = max(patterns, key=lambda x: x['true_cvr'])

    selected_counts = {p['pattern']: 0 for p in patterns}
    total_regret = 0

    for _ in range(n_simulations):
        # Thompson Sampling –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        samples = []

        for p in patterns:
            # –î–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏: alpha ~ conversions, beta ~ failures
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º true_cvr –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ alpha/beta
            alpha = p['true_cvr'] * 100 + 1
            beta = (1 - p['true_cvr']) * 100 + 1

            score = random.betavariate(alpha, beta)
            samples.append((p['pattern'], score, p['true_cvr']))

        # –í—ã–±—Ä–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω —Å highest score
        selected = max(samples, key=lambda x: x[1])
        selected_pattern, _, selected_cvr = selected

        selected_counts[selected_pattern] += 1

        # –í—ã—á–∏—Å–ª–∏—Ç—å regret
        regret = best_pattern['true_cvr'] - selected_cvr
        total_regret += regret

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    avg_regret = total_regret / n_simulations
    best_selected_pct = selected_counts[best_pattern['pattern']] / n_simulations
    exploration_rate = 1 - best_selected_pct

    return {
        "average_regret": round(avg_regret, 4),
        "average_regret_percent": round(avg_regret * 100, 2),
        "best_pattern_selected_pct": round(best_selected_pct, 3),
        "exploration_rate": round(exploration_rate, 3),
        "selected_counts": selected_counts,
        "n_simulations": n_simulations,
        "recommendation": (
            "Excellent balance!" if 0.7 <= best_selected_pct <= 0.85
            else "Too much exploration (increase sample size)" if best_selected_pct < 0.7
            else "Too much exploitation (add exploration bonus)"
        )
    }


if __name__ == "__main__":
    # –î–µ–º–æ: —Å–∏–º—É–ª—è—Ü–∏—è Thompson Sampling
    print("üé≤ Thompson Sampling Simulation")
    print("="*60)

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å —Ä–∞–∑–Ω—ã–º–∏ true CVR
    test_patterns = [
        {"pattern": "question + curiosity", "true_cvr": 0.15},  # Best
        {"pattern": "bold_claim + excitement", "true_cvr": 0.12},
        {"pattern": "wait + fear", "true_cvr": 0.08},
        {"pattern": "urgency + greed", "true_cvr": 0.10},
    ]

    result = simulate_thompson_sampling_performance(test_patterns, n_simulations=10000)

    print(f"\nBest pattern: question + curiosity (CVR=15%)")
    print(f"Average regret: {result['average_regret_percent']:.2f}%")
    print(f"Best pattern selected: {result['best_pattern_selected_pct']*100:.1f}% of time")
    print(f"Exploration rate: {result['exploration_rate']*100:.1f}%")
    print(f"\n{result['recommendation']}")

    print(f"\nSelection distribution:")
    for pattern, count in result['selected_counts'].items():
        pct = count / result['n_simulations'] * 100
        print(f"  {pattern}: {pct:.1f}%")
