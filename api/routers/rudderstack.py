"""
RudderStack Webhook Router - Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ†Ð¸Ñ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¹.

ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð¾Ñ‚ RudderStack:
- Page Viewed (UTM tracking)
- Order Completed (Conversion tracking)

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð‘Ð°Ð¹ÐµÑÐ¾Ð²ÑÐºÐ¾Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ (Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ) Ð´Ð»Ñ
Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð¿ÐµÑ€ÐµÑÑ‡ÐµÑ‚Ð° avg_cvr Ð² pattern_performance.
"""

from fastapi import APIRouter, Depends, HTTPException, Request
from sqlalchemy.orm import Session
from sqlalchemy import func
from sqlalchemy.sql import expression
from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import datetime
import uuid
import random
import numpy as np

# Ð‘Ð°Ð¹ÐµÑÐ¾Ð²ÑÐºÐ¾Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ
try:
    from scipy.stats import beta as beta_dist
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    import warnings
    warnings.warn("scipy not installed. Using simplified Bayesian update.")

from database.base import get_db
from database.models import (
    Creative, TrafficSource, Conversion,
    PatternPerformance, User
)
from utils.logger import setup_logger

logger = setup_logger(__name__)
router = APIRouter(prefix="/api/v1/rudderstack", tags=["RudderStack Integration"])


# ========== SCHEMAS ==========

class RudderStackEvent(BaseModel):
    """
    RudderStack event format.

    Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ: https://www.rudderstack.com/docs/event-spec/
    """
    event: str  # "Page Viewed", "Order Completed"
    userId: Optional[str] = None
    anonymousId: Optional[str] = None
    properties: Dict[str, Any]
    context: Optional[Dict[str, Any]] = None
    timestamp: Optional[str] = None


# ========== HELPERS ==========

def get_pattern_hash(creative: Creative) -> str:
    """
    Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ pattern_hash Ð¸Ð· Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð°.

    Ð”Ð»Ñ EdTech Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ target_audience_pain - ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ð°Ð¶Ð½Ð¾!
    """
    return (
        f"hook:{creative.hook_type or 'unknown'}"
        f"|emo:{creative.emotion or 'unknown'}"
        f"|pace:{creative.pacing or 'medium'}"
        f"|pain:{getattr(creative, 'target_audience_pain', None) or 'unknown'}"
        f"|cta:{creative.cta_type or 'unknown'}"
    )


def bayesian_update_cvr(
    total_conversions: int,
    total_clicks: int,
    alpha_prior: float = 1.0,
    beta_prior: float = 1.0
) -> tuple[float, float, float]:
    """
    Ð‘Ð°Ð¹ÐµÑÐ¾Ð²ÑÐºÐ¾Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ CVR Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ.

    Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¾:
    - alpha = ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑƒÑÐ¿ÐµÑ…Ð¾Ð² (conversions) + prior
    - beta = ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð½ÐµÑƒÐ´Ð°Ñ‡ (clicks - conversions) + prior

    Args:
        total_conversions: ÐžÐ±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¹
        total_clicks: ÐžÐ±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ»Ð¸ÐºÐ¾Ð²
        alpha_prior: Prior Ð´Ð»Ñ Beta (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 1 = uniform prior)
        beta_prior: Prior Ð´Ð»Ñ Beta (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 1 = uniform prior)

    Returns:
        (mean_cvr, lower_95, upper_95) - ÑÑ€ÐµÐ´Ð½Ð¸Ð¹ CVR Ð¸ 95% Ð´Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»

    ÐŸÑ€Ð¸Ð¼ÐµÑ€:
        total_conversions=10, total_clicks=100
        â†’ alpha = 10 + 1 = 11
        â†’ beta = 90 + 1 = 91
        â†’ mean = 11/(11+91) = 10.8%
        â†’ CI: [5.7%, 17.8%]
    """

    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ alpha Ð¸ beta
    # alpha = ÑƒÑÐ¿ÐµÑ…Ð¸ (conversions)
    # beta = Ð½ÐµÑƒÐ´Ð°Ñ‡Ð¸ (clicks - conversions)
    alpha = alpha_prior + total_conversions
    beta_param = beta_prior + (total_clicks - total_conversions)

    # Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ: alpha / (alpha + beta)
    mean_cvr = alpha / (alpha + beta_param)

    # 95% Ð´Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»
    if SCIPY_AVAILABLE:
        # Ð¢Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ€Ð°ÑÑ‡ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· scipy
        lower_bound = beta_dist.ppf(0.025, alpha, beta_param)
        upper_bound = beta_dist.ppf(0.975, alpha, beta_param)
    else:
        # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ñ€Ð°ÑÑ‡ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· variance
        variance = (alpha * beta_param) / ((alpha + beta_param) ** 2 * (alpha + beta_param + 1))
        std_dev = variance ** 0.5
        lower_bound = max(0, mean_cvr - 1.96 * std_dev)
        upper_bound = min(1, mean_cvr + 1.96 * std_dev)

    return mean_cvr, lower_bound, upper_bound


def thompson_sampling(patterns: list[PatternPerformance], n_samples: int = 5) -> list[dict]:
    """
    Thompson Sampling Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² Ð½Ð° Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ.

    Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°:
    1. Ð‘ÐµÑ€ÐµÐ¼ bayesian_alpha, bayesian_beta Ð¸Ð· Ð‘Ð” (ÑƒÐ¶Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑŽÑ‚ÑÑ Ð°Ñ‚Ð¾Ð¼Ð°Ñ€Ð½Ð¾)
    2. Ð”ÐµÐ»Ð°ÐµÐ¼ sample = numpy.random.beta(alpha, beta)
    3. ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ weight multiplier (benchmark patterns Ð¸Ð¼ÐµÑŽÑ‚ Ð²ÐµÑ 2.0)
    4. Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ weighted_score (Ð²Ñ‹ÑˆÐµ = Ð»ÑƒÑ‡ÑˆÐµ)
    5. Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ top-N

    Ð‘Ð°Ð»Ð°Ð½Ñ Exploration vs Exploitation:
    - ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¼ CVR Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¾Ð¹ â†’ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹ sample (exploit)
    - ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ñ Ð¼Ð°Ð»Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¾Ð¹ â†’ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ð²Ð°Ñ€Ð¸Ð°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ sample (explore)
    - Benchmark Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ (weight=2.0) Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÑŽÑ‚ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚

    Args:
        patterns: Ð¡Ð¿Ð¸ÑÐ¾Ðº PatternPerformance Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²
        n_samples: Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ñ‚ÑŒ

    Returns:
        Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ñ thompson_score
    """

    recommendations = []

    for pattern in patterns:
        # Beta Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð· Ð‘Ð” (Ð°Ñ‚Ð¾Ð¼Ð°Ñ€Ð½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑŽÑ‚ÑÑ Ð² Ð²ÐµÐ±Ñ…ÑƒÐºÐ°Ñ…)
        alpha = pattern.bayesian_alpha or 1.0
        beta_param = pattern.bayesian_beta or 1.0

        # Thompson Sampling: ÑÑÐ¼Ð¿Ð»Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð· Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ numpy Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        thompson_score = np.random.beta(alpha, beta_param)

        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÑ€ÐµÐ´Ð½ÐµÐµ CVR = Î± / (Î± + Î²)
        mean_cvr = alpha / (alpha + beta_param)

        # Weight multiplier (benchmark=2.0, client=1.0)
        weight = pattern.weight or 1.0

        # Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ score Ð´Ð»Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸
        weighted_score = thompson_score * weight

        recommendations.append({
            "pattern_hash": pattern.pattern_hash,
            "hook_type": pattern.hook_type,
            "emotion": pattern.emotion,
            "pacing": pattern.pacing,
            "psychotype": pattern.psychotype,
            "thompson_score": float(thompson_score),  # Ð”Ð»Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸
            "weighted_score": float(weighted_score),
            "mean_cvr": float(mean_cvr),
            "sample_size": pattern.sample_size or 0,
            "total_conversions": pattern.total_conversions or 0,
            "alpha": float(alpha),
            "beta": float(beta_param),
            "weight": float(weight),
            "source": pattern.source or 'client',
            "reasoning": (
                f"Benchmark winner (n={pattern.sample_size}, weight={weight}x)" if pattern.source == 'benchmark'
                else f"High confidence winner (n={pattern.sample_size})" if pattern.sample_size and pattern.sample_size > 20
                else f"Promising, needs more data (n={pattern.sample_size or 0})" if pattern.sample_size and pattern.sample_size > 5
                else "New pattern, high exploration value"
            )
        })

    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ weighted_score (Ð²Ñ‹ÑˆÐµ = Ð»ÑƒÑ‡ÑˆÐµ)
    recommendations.sort(key=lambda x: x['weighted_score'], reverse=True)

    return recommendations[:n_samples]


# ========== ENDPOINTS ==========

@router.post("/track")
async def rudderstack_webhook(
    event: RudderStackEvent,
    request: Request,
    db: Session = Depends(get_db)
):
    """
    Webhook Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð¾Ñ‚ RudderStack.

    Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ñ:
    1. "Page Viewed" â†’ Ð¢Ñ€ÐµÐºÐ°ÐµÐ¼ UTM, ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ user_session
    2. "Order Completed" â†’ Ð¢Ñ€ÐµÐºÐ°ÐµÐ¼ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸ÑŽ, Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ML Ð¼Ð¾Ð´ÐµÐ»ÑŒ

    Example payload:
    ```json
    {
      "event": "Order Completed",
      "userId": "user_123",
      "anonymousId": "anon_456",
      "properties": {
        "order_id": "ord_789",
        "total": 50.00,
        "currency": "USD",
        "utm_id": "creative_abc123"  // Ð¸Ð»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð· context
      },
      "context": {
        "campaign": {
          "source": "instagram",
          "medium": "influencer",
          "name": "jan_fitness"
        }
      }
    }
    ```
    """

    logger.info(f"RudderStack event: {event.event} from {event.userId or event.anonymousId}")

    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ customer_id (userId Ð¸Ð»Ð¸ anonymousId)
    customer_id = event.userId or event.anonymousId

    if not customer_id:
        logger.warning("No userId or anonymousId in RudderStack event")
        return {"success": False, "error": "Missing customer identifier"}

    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹
    if event.event == "Page Viewed":
        return await handle_page_view(event, customer_id, db)

    elif event.event == "Video View":
        return await handle_video_view(event, customer_id, db)

    elif event.event == "Order Completed":
        return await handle_order_completed(event, customer_id, db)

    else:
        logger.info(f"Ignoring event type: {event.event}")
        return {"success": True, "message": f"Event {event.event} logged"}


async def handle_page_view(
    event: RudderStackEvent,
    customer_id: str,
    db: Session
) -> Dict:
    """
    ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Page Viewed - ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ UTM ÑÐµÑÑÐ¸Ð¸.

    Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ utm_id Ð¸Ð·:
    1. properties.utm_id
    2. context.campaign (utm_source, utm_campaign)
    3. URL parameters
    """

    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ UTM
    utm_id = event.properties.get("utm_id")

    if not utm_id and event.context:
        # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð¸Ð· context.campaign
        campaign = event.context.get("campaign", {})
        if campaign:
            # Ð˜Ñ‰ÐµÐ¼ traffic_source Ð¿Ð¾ utm_campaign
            utm_campaign = campaign.get("name")
            if utm_campaign:
                ts = db.query(TrafficSource).filter(
                    TrafficSource.utm_campaign == utm_campaign
                ).first()

                if ts:
                    utm_id = ts.utm_id

    if not utm_id:
        logger.warning(f"No UTM found in Page Viewed event for {customer_id}")
        return {"success": False, "error": "No UTM found"}

    # ÐÐ°Ð¹Ñ‚Ð¸ traffic_source
    traffic_source = db.query(TrafficSource).filter(
        TrafficSource.utm_id == utm_id
    ).first()

    if not traffic_source:
        logger.warning(f"Traffic source not found: {utm_id}")
        return {"success": False, "error": "Traffic source not found"}

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ/Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ user_session
    from database.models import UserSession

    session = db.query(UserSession).filter(
        UserSession.customer_id == customer_id,
        UserSession.utm_id == utm_id
    ).first()

    if session:
        # ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÑÐµÑÑÐ¸ÑŽ
        session.last_interaction = datetime.utcnow()
        session.touch_count += 1
    else:
        # Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ ÑÐµÑÑÐ¸ÑŽ
        session = UserSession(
            id=uuid.uuid4(),
            customer_id=customer_id,
            external_id=event.anonymousId,
            utm_id=utm_id,
            traffic_source_id=traffic_source.id,
            creative_id=traffic_source.creative_id,
            first_interaction=datetime.utcnow(),
            device_type=event.context.get("device", {}).get("type") if event.context else None,
            ip_address=event.context.get("ip") if event.context else None
        )
        db.add(session)

    # ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÐºÐ»Ð¸ÐºÐ¸ Ð² traffic_source
    traffic_source.clicks += 1
    traffic_source.last_click = datetime.utcnow()
    traffic_source.external_id = event.anonymousId

    db.commit()

    logger.info(f"User session tracked: {customer_id} â†’ {utm_id}")

    return {
        "success": True,
        "message": "Page view tracked",
        "utm_id": utm_id,
        "customer_id": customer_id
    }


async def handle_video_view(
    event: RudderStackEvent,
    customer_id: str,
    db: Session
) -> Dict:
    """
    ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Video View - Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚ Î² (Ð½ÐµÑƒÐ´Ð°Ñ‡Ð¸) Ð´Ð»Ñ Thompson Sampling.

    ÐŸÑ€Ð¸ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð‘Ð•Ð— ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¸ - ÑÑ‚Ð¾ "Ð½ÐµÑƒÐ´Ð°Ñ‡Ð°" Ð² Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ñ… Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ.
    Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ bayesian_beta Ð´Ð»Ñ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð° ÐÐ¢ÐžÐœÐÐ ÐÐž.

    Args:
        event: RudderStack ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ
        customer_id: ID Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        db: Database session

    Returns:
        Dict Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
    """

    # Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ creative_id Ð¸Ð· properties
    creative_id_str = event.properties.get("creative_id")

    if not creative_id_str:
        logger.warning(f"No creative_id in Video View event for {customer_id}")
        return {"success": False, "error": "No creative_id found"}

    try:
        creative_id = uuid.UUID(creative_id_str)
    except ValueError:
        logger.error(f"Invalid creative_id format: {creative_id_str}")
        return {"success": False, "error": "Invalid creative_id"}

    # ÐÐ°Ð¹Ñ‚Ð¸ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²
    creative = db.query(Creative).filter(Creative.id == creative_id).first()

    if not creative:
        logger.warning(f"Creative not found: {creative_id}")
        return {"success": False, "error": "Creative not found"}

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ pattern_hash
    pattern_hash = get_pattern_hash(creative)

    # ÐÐ°Ð¹Ñ‚Ð¸ Ð¸Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ pattern_performance
    pattern_perf = db.query(PatternPerformance).filter(
        PatternPerformance.pattern_hash == pattern_hash,
        PatternPerformance.product_category == creative.product_category
    ).first()

    if pattern_perf:
        # ðŸ”¥ ÐÐ¢ÐžÐœÐÐ ÐÐ«Ð™ Ð˜ÐÐšÐ Ð•ÐœÐ•ÐÐ¢ Î² (Ð½ÐµÑƒÐ´Ð°Ñ‡Ð¸)
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ F-expression Ð´Ð»Ñ Ð¸Ð·Ð±ÐµÐ¶Ð°Ð½Ð¸Ñ race condition
        db.query(PatternPerformance).filter(
            PatternPerformance.id == pattern_perf.id
        ).update({
            "bayesian_beta": PatternPerformance.bayesian_beta + 1,
            "total_clicks": PatternPerformance.total_clicks + 1,
            "updated_at": datetime.utcnow()
        }, synchronize_session=False)

        db.commit()

        # ÐŸÐµÑ€ÐµÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ avg_cvr Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Î± Ð¸ Î²
        # Refresh Ð¾Ð±ÑŠÐµÐºÑ‚ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        db.refresh(pattern_perf)

        alpha = pattern_perf.bayesian_alpha
        beta_val = pattern_perf.bayesian_beta

        # Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ CVR = Î± / (Î± + Î²)
        mean_cvr = alpha / (alpha + beta_val)

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ avg_cvr
        pattern_perf.avg_cvr = int(mean_cvr * 10000)
        db.commit()

        logger.info(
            f"Pattern Î² incremented: {pattern_hash} | "
            f"Î±={alpha}, Î²={beta_val} | "
            f"CVR={mean_cvr*100:.2f}%"
        )
    else:
        # Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ñ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ prior
        # Ð”Ð»Ñ Ð½Ð¾Ð²Ñ‹Ñ… ÐºÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ¸Ñ… Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²: Î±=1, Î²=2 (1 Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð±ÐµÐ· ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¸)
        pattern_perf = PatternPerformance(
            id=uuid.uuid4(),
            user_id=creative.user_id,
            pattern_hash=pattern_hash,
            hook_type=creative.hook_type,
            emotion=creative.emotion,
            pacing=creative.pacing,
            cta_type=creative.cta_type,
            target_audience_pain=getattr(creative, 'target_audience_pain', None),
            psychotype=getattr(creative, 'psychotype', None),
            product_category=creative.product_category,
            source='client',
            weight=1.0,
            bayesian_alpha=1.0,  # Neutral prior
            bayesian_beta=2.0,   # +1 Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð° Ð±ÐµÐ· ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¸
            sample_size=0,
            total_conversions=0,
            total_clicks=1,
            avg_cvr=int(0.33 * 10000),  # Î±/(Î±+Î²) = 1/3 = 33%
            created_at=datetime.utcnow()
        )
        db.add(pattern_perf)
        db.commit()

        logger.info(f"New pattern created from Video View: {pattern_hash}")

    return {
        "success": True,
        "message": "Video view tracked (Î² incremented)",
        "creative_id": str(creative.id),
        "pattern_hash": pattern_hash,
        "bayesian_alpha": pattern_perf.bayesian_alpha,
        "bayesian_beta": pattern_perf.bayesian_beta
    }


async def handle_order_completed(
    event: RudderStackEvent,
    customer_id: str,
    db: Session
) -> Dict:
    """
    ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Order Completed - Ð°Ð²Ñ‚Ð¾Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ†Ð¸Ñ + Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ML.

    ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼:
    1. ÐÐ°Ð¹Ñ‚Ð¸ user_session Ð¿Ð¾ customer_id (last-click attribution)
    2. ÐÐ°Ð¹Ñ‚Ð¸ traffic_source Ð¸ creative
    3. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ conversion Ð·Ð°Ð¿Ð¸ÑÑŒ
    4. ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ creative Ð¸ traffic_source
    5. ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ pattern_performance Ñ Ð‘Ð°Ð¹ÐµÑÐ¾Ð²ÑÐºÐ¸Ð¼ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð¼
    """

    # 1. ÐÐ°Ð¹Ñ‚Ð¸ ÑÐµÑÑÐ¸ÑŽ (last-click attribution)
    from database.models import UserSession

    session = db.query(UserSession).filter(
        UserSession.customer_id == customer_id
    ).order_by(UserSession.last_interaction.desc()).first()

    if not session:
        logger.warning(f"No session found for customer: {customer_id}")
        return {"success": False, "error": "No attribution data found"}

    # 2. ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ traffic_source Ð¸ creative
    traffic_source = db.query(TrafficSource).filter(
        TrafficSource.id == session.traffic_source_id
    ).first()

    creative = db.query(Creative).filter(
        Creative.id == session.creative_id
    ).first() if session.creative_id else None

    if not traffic_source:
        logger.error(f"Traffic source not found: {session.traffic_source_id}")
        return {"success": False, "error": "Traffic source not found"}

    # Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð¿Ð¾ÐºÑƒÐ¿ÐºÐµ
    amount_cents = int(event.properties.get("total", 0) * 100)  # USD to cents
    currency = event.properties.get("currency", "USD")
    order_id = event.properties.get("order_id")

    # 3. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ conversion
    time_to_conversion = int((datetime.utcnow() - session.first_interaction).total_seconds())

    conversion = Conversion(
        id=uuid.uuid4(),
        traffic_source_id=traffic_source.id,
        user_id=traffic_source.user_id,
        conversion_type="purchase",
        customer_id=customer_id,
        amount=amount_cents,
        currency=currency,
        product_id=order_id,
        product_name=event.properties.get("product_name", "Product"),
        time_to_conversion=time_to_conversion,
        extra_data=event.properties,
        external_id=event.anonymousId,
        created_at=datetime.utcnow()
    )

    db.add(conversion)

    # 4. ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ traffic_source
    traffic_source.conversions = (traffic_source.conversions or 0) + 1
    traffic_source.revenue = (traffic_source.revenue or 0) + amount_cents

    # 5. ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ creative (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
    if creative:
        creative.conversions = (creative.conversions or 0) + 1
        creative.revenue = (creative.revenue or 0) + amount_cents

        # ÐŸÐµÑ€ÐµÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ CVR ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð°
        if creative.impressions and creative.impressions > 0:
            creative.cvr = int((creative.conversions / creative.impressions) * 10000)

        creative.last_stats_update = datetime.utcnow()

        # ðŸŽ¯ TRIGGER DEEP ANALYSIS (ÐµÑÐ»Ð¸ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð² Ð´Ð¾ÑÑ‚Ð¸Ð³ Ð¿Ð¾Ñ€Ð¾Ð³Ð°)
        from utils.analysis_orchestrator import check_analysis_trigger
        try:
            check_analysis_trigger(creative.id, db)
        except Exception as analysis_error:
            logger.warning(f"Analysis trigger failed: {analysis_error}")

        # 6. ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ pattern_performance Ñ Ð‘Ð°Ð¹ÐµÑÐ¾Ð²ÑÐºÐ¸Ð¼ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð¼
        pattern_hash = get_pattern_hash(creative)

        pattern_perf = db.query(PatternPerformance).filter(
            PatternPerformance.pattern_hash == pattern_hash,
            PatternPerformance.product_category == creative.product_category
        ).first()

        if pattern_perf:
            # ðŸ”¥ ÐÐ¢ÐžÐœÐÐ ÐÐ«Ð™ Ð˜ÐÐšÐ Ð•ÐœÐ•ÐÐ¢ Î± (ÑƒÑÐ¿ÐµÑ…Ð¸)
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ F-expression Ð´Ð»Ñ Ð¸Ð·Ð±ÐµÐ¶Ð°Ð½Ð¸Ñ race condition
            db.query(PatternPerformance).filter(
                PatternPerformance.id == pattern_perf.id
            ).update({
                "bayesian_alpha": PatternPerformance.bayesian_alpha + 1,
                "total_conversions": PatternPerformance.total_conversions + 1,
                "sample_size": PatternPerformance.sample_size + 1,
                "updated_at": datetime.utcnow()
            }, synchronize_session=False)

            db.commit()

            # ÐŸÐµÑ€ÐµÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ avg_cvr Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Î± Ð¸ Î²
            # Refresh Ð¾Ð±ÑŠÐµÐºÑ‚ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
            db.refresh(pattern_perf)

            alpha = pattern_perf.bayesian_alpha
            beta_val = pattern_perf.bayesian_beta

            # Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ CVR = Î± / (Î± + Î²)
            mean_cvr = alpha / (alpha + beta_val)

            # Ð”Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ scipy ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½)
            if SCIPY_AVAILABLE:
                lower_bound = beta_dist.ppf(0.025, alpha, beta_val)
                upper_bound = beta_dist.ppf(0.975, alpha, beta_val)
            else:
                # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ñ€Ð°ÑÑ‡ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· variance
                variance = (alpha * beta_val) / ((alpha + beta_val) ** 2 * (alpha + beta_val + 1))
                std_dev = variance ** 0.5
                lower_bound = max(0, mean_cvr - 1.96 * std_dev)
                upper_bound = min(1, mean_cvr + 1.96 * std_dev)

            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼Ñ‹Ðµ Ð¿Ð¾Ð»Ñ
            pattern_perf.avg_cvr = int(mean_cvr * 10000)
            pattern_perf.confidence_interval_lower = int(lower_bound * 10000)
            pattern_perf.confidence_interval_upper = int(upper_bound * 10000)
            db.commit()

            logger.info(
                f"Pattern Î± incremented: {pattern_hash} | "
                f"Î±={alpha}, Î²={beta_val} | "
                f"CVR={mean_cvr*100:.2f}% (CI: {lower_bound*100:.1f}%-{upper_bound*100:.1f}%) | "
                f"n={pattern_perf.sample_size}"
            )
        else:
            # Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½
            # Ð”Ð»Ñ benchmark Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²: Î±=50, Î²=950 (5% CVR, Ð½Ð¸Ð·ÐºÐ°Ñ Ð´Ð¸ÑÐ¿ÐµÑ€ÑÐ¸Ñ)
            # Ð”Ð»Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ¸Ñ… Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²: Î±=2, Î²=1 (Ð¿ÐµÑ€Ð²Ð°Ñ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ñ)
            is_benchmark = getattr(creative, 'is_benchmark', False)

            if is_benchmark:
                # Benchmark prior: Î±=50, Î²=950 â†’ CVR = 50/1000 = 5%
                initial_alpha = 50.0
                initial_beta = 950.0
                source = 'benchmark'
                weight = 2.0
            else:
                # Client prior: Î±=2, Î²=1 (Ð¿ÐµÑ€Ð²Ð°Ñ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ñ, Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ prior)
                initial_alpha = 2.0
                initial_beta = 1.0
                source = 'client'
                weight = 1.0

            mean_cvr = initial_alpha / (initial_alpha + initial_beta)

            pattern_perf = PatternPerformance(
                id=uuid.uuid4(),
                user_id=traffic_source.user_id,
                pattern_hash=pattern_hash,
                hook_type=creative.hook_type,
                emotion=creative.emotion,
                pacing=creative.pacing,
                cta_type=creative.cta_type,
                target_audience_pain=getattr(creative, 'target_audience_pain', None),
                psychotype=getattr(creative, 'psychotype', None),
                product_category=creative.product_category,
                source=source,
                weight=weight,
                bayesian_alpha=initial_alpha,
                bayesian_beta=initial_beta,
                sample_size=1,
                total_conversions=1,
                total_clicks=1,
                avg_cvr=int(mean_cvr * 10000),
                confidence_interval_lower=0,
                confidence_interval_upper=int(1.0 * 10000),
                created_at=datetime.utcnow()
            )
            db.add(pattern_perf)

            logger.info(
                f"New pattern created: {pattern_hash} | "
                f"source={source}, Î±={initial_alpha}, Î²={initial_beta}"
            )

    db.commit()

    logger.info(
        f"Conversion tracked: {customer_id} â†’ {session.utm_id} â†’ "
        f"{creative.name if creative else 'N/A'} | ${amount_cents/100:.2f}"
    )

    return {
        "success": True,
        "message": "Order completed and attributed",
        "conversion_id": str(conversion.id),
        "utm_id": session.utm_id,
        "creative_id": str(creative.id) if creative else None,
        "amount": amount_cents / 100,
        "pattern_updated": creative is not None
    }


@router.get("/thompson-sampling")
async def get_thompson_sampling_recommendations(
    product_category: str = "language_learning",
    n_recommendations: int = 5,
    db: Session = Depends(get_db)
):
    """
    Thompson Sampling Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ - ÐºÐ°ÐºÐ¸Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ñ‚ÐµÑÑ‚Ð¸Ñ‚ÑŒ Ð´Ð°Ð»ÑŒÑˆÐµ.

    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ random.betavariate(alpha, beta) Ð´Ð»Ñ ÑÑÐ¼Ð¿Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸Ð·
    Beta-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°.

    Ð‘Ð°Ð»Ð°Ð½Ñ Exploration vs Exploitation:
    - Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ CVR + Ð¼Ð½Ð¾Ð³Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… = ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹ sample (exploit)
    - ÐœÐ°Ð»Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… = Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ð²Ð°Ñ€Ð¸Ð°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ sample (explore)

    Example:
        GET /thompson-sampling?product_category=fitness&n_recommendations=3

    Returns:
        [
            {
                "pattern_hash": "hook:before_after|emo:achievement|...",
                "hook_type": "before_after",
                "emotion": "achievement",
                "thompson_score": 0.15,  # Sampled value
                "mean_cvr": 0.12,        # Expected CVR
                "alpha": 13,             # Beta params
                "beta": 95,
                "sample_size": 10,
                "reasoning": "High confidence winner (n=10)"
            },
            ...
        ]
    """

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸
    patterns = db.query(PatternPerformance).filter(
        PatternPerformance.product_category == product_category,
        PatternPerformance.sample_size > 0
    ).all()

    if not patterns:
        return {
            "recommendations": [],
            "message": f"No patterns found for {product_category}"
        }

    # Thompson Sampling
    recommendations = thompson_sampling(patterns, n_samples=n_recommendations)

    return {
        "product_category": product_category,
        "n_patterns_evaluated": len(patterns),
        "recommendations": recommendations,
        "algorithm": "Thompson Sampling with Beta prior",
        "note": "thompson_score is sampled from Beta(alpha, beta). Higher = recommend testing this pattern next."
    }
